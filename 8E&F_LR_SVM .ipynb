{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "8E&F_LR_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HExLQrE4ZxR"
      },
      "source": [
        "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LuKrFzC4ZxV"
      },
      "source": [
        "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wES-wWN4ZxX"
      },
      "source": [
        "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
        "\n",
        "Check the documentation for better understanding of these attributes: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
        "\n",
        "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
        "\n",
        "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
        "\n",
        "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
        "\n",
        "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
        "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
        "\n",
        "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
        "\n",
        "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z830CfMk4Zxa"
      },
      "source": [
        "## Task E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuBxHiCQ4Zxc"
      },
      "source": [
        "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
        "\n",
        "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
        "\n",
        "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCgMNEvI4Zxf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import exp\n",
        "import  math"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUNIqCe4Zxn"
      },
      "source": [
        "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu7WMEU1t9Bf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.40, random_state=15)\n",
        "X_test, X_cv,y_test,y_cv=train_test_split(X_test,y_test, test_size=.50, random_state=15)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHie1zqH4Zxt"
      },
      "source": [
        "### Pseudo code\n",
        "\n",
        "clf = SVC(gamma=0.001, C=100.)<br>\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
        "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
        "    \n",
        "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
        "\n",
        "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZftfYyYJiEVy",
        "outputId": "2e79b578-0b37-40a4-cc49-e7b0ed93a3c5"
      },
      "source": [
        "# you can write your code here\n",
        "clf = SVC(gamma=0.001, C=100)\n",
        "clf.fit(X_train,y_train)\n",
        "support_vectors=clf.support_vectors_\n",
        "intercept=clf.intercept_\n",
        "dual_coe=clf.dual_coef_\n",
        "\n",
        "def kernal(mat1, mat2, gamma):\n",
        "    \n",
        "    k=exp(-gamma*np.sum((mat1-mat2)**2))\n",
        "    \n",
        "\n",
        "    return k\n",
        "\n",
        "\n",
        "gamma=0.001\n",
        "def decision_function(gamma,X_cv,dual_coe,intercept,support_vectors):\n",
        "        result_dec_fn=[]\n",
        "        for j in X_cv:\n",
        "            tmp=0\n",
        "            for i,k in zip(support_vectors,dual_coe[0]):\n",
        "               Ker=kernal(i,j,gamma)\n",
        "               tmp+=(k*Ker)\n",
        "            tmp=tmp+intercept \n",
        "            result_dec_fn.append(tmp)    \n",
        "        return result_dec_fn\n",
        "           \n",
        "result_dec_functn=decision_function(gamma,X_cv,dual_coe,intercept,support_vectors)\n",
        "result_list=list(i[0] for i in result_dec_functn)\n",
        "print(\"output of decision funcation \" ,result_list[0:10])\n",
        "F_cv =[]\n",
        "for i in result_list:\n",
        "    if i>0:\n",
        "        F_cv.append(1)\n",
        "    else:\n",
        "        F_cv.append(0)       \n",
        "\n",
        "print(\"output of model \",clf.decision_function(X_cv)[0:10])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output of decision funcation  [-2.15980217966647, -2.6315643052289905, -3.610567063094037, 1.9254014334365632, -0.9839950024528423, -1.84103624132939, -3.0473972987289804, -0.9108054741150926, -1.0738614096121768, -2.8494875264428563]\n",
            "output of model  [-2.15980218 -2.63156431 -3.61056706  1.92540143 -0.983995   -1.84103624\n",
            " -3.0473973  -0.91080547 -1.07386141 -2.84948753]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0bKCboN4Zxu"
      },
      "source": [
        "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMn7OEN94Zxw"
      },
      "source": [
        "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
        "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0n5EFkx4Zxz"
      },
      "source": [
        "## TASK F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0HOqVJq4Zx1"
      },
      "source": [
        "\n",
        "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
        "\n",
        "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
        "\n",
        "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
        "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
        "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
        "\n",
        "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAXGPL6oy6ul"
      },
      "source": [
        "no_of_plus=np.count_nonzero(y_train==1)\n",
        "no_of_minus=np.count_nonzero(y_train==0)\n",
        "\n",
        "y_plus=(no_of_plus+1)/(no_of_minus+2)\n",
        "y_minus=1/(no_of_minus+2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_cXGLkdCfHQ"
      },
      "source": [
        "def predict(y_cv):\n",
        "    y_cv_predict=np.where(y_cv==0,y_minus,y_plus)\n",
        "    return y_cv_predict\n",
        "\n",
        "y_cv_pred=predict(y_cv)  \n",
        "\n",
        "F_test=clf.decision_function(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXEjwjXjDbWs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sE3wOnA1gvz",
        "outputId": "74ad8172-afe1-480a-a3a2-25fc1d0c77d1"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "   w=np.zeros_like(dim)\n",
        "   b=0\n",
        "   return w,b\n",
        "\n",
        "def sigmoid(z):\n",
        " sig_z=(1/(1+np.exp(-z)))\n",
        " return sig_z\n",
        "\n",
        "def logloss(y_true,y_pred): \n",
        "\n",
        "   loss =0\n",
        "   for i in range(len(y_true)):\n",
        "       temp=y_true[i]*math.log10(y_pred[i])+(1-y_true[i])*math.log10(1-y_pred[i])\n",
        "       loss+=temp\n",
        "   loss=(-1*loss)/len(y_true)\n",
        "   return loss\n",
        "\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw=x*(y-sigmoid(np.dot(w,x)+b)) -(alpha/N)*w\n",
        "    return dw\n",
        "\n",
        "def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "    db=y-(sigmoid(np.dot(w,x)+b))\n",
        "    return db\n",
        "\n",
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    w,b = initialize_weights(X_train[0])\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    for e in range(epochs):\n",
        "       \n",
        "        for x,y in zip(X_train,y_train):\n",
        "            dw = gradient_dw(x,y,w,b,alpha,N)\n",
        "            db = gradient_db(x,y,w,b)\n",
        "            w = w + (eta0 * dw)\n",
        "            b = b + (eta0 * db)\n",
        "        \n",
        "        train_pred = []\n",
        "        \n",
        "        for i in X_train:\n",
        "            y_pred= sigmoid(np.dot(w,i) + b)\n",
        "            train_pred.append(y_pred)\n",
        "        loss1=logloss(y_train, train_pred)\n",
        "        train_loss.append(loss1) \n",
        "        \n",
        "        \n",
        "    return w,b,train_loss\n",
        "\n",
        "\n",
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(result_list)\n",
        "epochs=100\n",
        "w,b,train_loss=train(result_list,y_cv_pred ,F_test,y_test,epochs,alpha,eta0)\n",
        "print(\"W={}  intercept={}\".format(w,b))\n",
        "\n",
        "print(\"train_loss =\",train_loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W=0.7836275055532742  intercept=-1.1641575400972337\n",
            "train_loss = [0.2738898730674267, 0.25292270156343827, 0.23653510496818148, 0.223538334974367, 0.21306885628487032, 0.20450422190302345, 0.1973944243909419, 0.19141126585906384, 0.18631259588648674, 0.18191745822119545, 0.1780888604132711, 0.17472176924067384, 0.17173467282292865, 0.16906358533578106, 0.16665773729347866, 0.16447644049690363, 0.16248678059572427, 0.16066189939558828, 0.1589797022027556, 0.15742187492274887, 0.15597312933760984, 0.15462061821151918, 0.15335347804529983, 0.15216246867761588, 0.15103968701810322, 0.14997833800423616, 0.1489725500831522, 0.14801722559971103, 0.14710791874588794, 0.14624073541959998, 0.145412250611909, 0.1446194399029328, 0.1438596223794855, 0.14313041284987219, 0.1424296816658115, 0.14175552079947107, 0.14110621508807586, 0.14048021776675423, 0.1398761295750996, 0.13929268085409002, 0.13872871615493573, 0.13818318096579313, 0.13765511023041202, 0.13714361838808004, 0.1366478907092743, 0.13616717573831205, 0.13570077868457778, 0.1352480556288902, 0.13480840843226496, 0.13438128025149873, 0.1339661515803394, 0.1335625367469777, 0.1331699808086555, 0.13278805679263767, 0.13241636323994632, 0.1320545220142925, 0.1317021763437721, 0.1313589890672654, 0.13102464106119846, 0.13069882982551373, 0.13038126821043153, 0.13007168326792545, 0.12976981521386893, 0.12947541648853514, 0.1291882509046684, 0.1289080928736239, 0.12863472670123563, 0.12836794594603904, 0.12810755283335007, 0.12785335771944092, 0.12760517860072793, 0.12736284066344375, 0.12712617586978112, 0.12689502257694074, 0.12666922518590154, 0.12644863381707616, 0.12623310401032153, 0.1260224964470405, 0.12581667669234725, 0.12561551495548254, 0.1254188858668472, 0.12522666827019263, 0.12503874502865037, 0.12485500284341938, 0.1246753320840374, 0.12449962662928052, 0.12432778371781236, 0.12415970380780333, 0.12399529044480304, 0.1238344501372222, 0.12367709223883644, 0.12352312883778344, 0.12337247465156713, 0.1232250469276289, 0.12308076534908659, 0.12293955194527487, 0.12280133100675049, 0.12266602900446225, 0.12253357451280165, 0.12240389813627972]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "rxU4Dfv1ZlB-",
        "outputId": "3f5e00df-3e65-499f-cbd8-8f380be38738"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs=list(range(1,101))\n",
        "plt.plot(epochs, train_loss, label=\"trainloss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"epoch number vs train  loss\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTY7z2bd4Zx2"
      },
      "source": [
        "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM3odN1Z4Zx3"
      },
      "source": [
        "\n",
        "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
        "\n",
        "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
        "\n",
        "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
        "\n",
        "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
        "\n",
        "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
      ]
    }
  ]
}