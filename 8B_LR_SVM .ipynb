{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "8B_LR_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ArWK463kbhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "56ec5a38-a373-4e82-921e-6db00af6f991"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mldzJdakbhS"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/temp/Linear model/task_b.csv')\n",
        "data=data.iloc[:,1:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhy3QXUqlAJf",
        "outputId": "066aa64c-71ad-4aff-db6b-12b9f784f29e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rsCrC2wckbhV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "12a04399-f278-4e06-b2bb-098511a588df"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-195.871045</td>\n",
              "      <td>-14843.084171</td>\n",
              "      <td>5.532140</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1217.183964</td>\n",
              "      <td>-4068.124621</td>\n",
              "      <td>4.416082</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.138451</td>\n",
              "      <td>4413.412028</td>\n",
              "      <td>0.425317</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>363.824242</td>\n",
              "      <td>15474.760647</td>\n",
              "      <td>1.094119</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-768.812047</td>\n",
              "      <td>-7963.932192</td>\n",
              "      <td>1.870536</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            f1            f2        f3    y\n",
              "0  -195.871045 -14843.084171  5.532140  1.0\n",
              "1 -1217.183964  -4068.124621  4.416082  1.0\n",
              "2     9.138451   4413.412028  0.425317  0.0\n",
              "3   363.824242  15474.760647  1.094119  0.0\n",
              "4  -768.812047  -7963.932192  1.870536  0.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI18joJ_kbhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b0b635-ebb3-4c8c-f455-8fdd5a98652a"
      },
      "source": [
        "data.corr()['y']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "f1    0.067172\n",
              "f2   -0.017944\n",
              "f3    0.839060\n",
              "y     1.000000\n",
              "Name: y, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "u40oCVMikbhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ab8da8-24d2-448a-b3c7-96c0023f5f02"
      },
      "source": [
        "data.std()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "f1      488.195035\n",
              "f2    10403.417325\n",
              "f3        2.926662\n",
              "y         0.501255\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQIbNaHskbhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49cd0f8-5da3-4470-f9cd-d8c011248dd9"
      },
      "source": [
        "X=data[['f1','f2','f3']].values\n",
        "Y=data['y'].values\n",
        "print(X.shape)\n",
        "\n",
        "print(Y.shape)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 3)\n",
            "(200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUxp9-qEkbhh"
      },
      "source": [
        "# What if our features are with different variance \n",
        "\n",
        "<pre>\n",
        "* <b>As part of this task you will observe how linear models work in case of data having feautres with different variance</b>\n",
        "* <b>from the output of the above cells you can observe that var(F2)>>var(F1)>>Var(F3)</b>\n",
        "\n",
        "> <b>Task1</b>:\n",
        "    1. Apply Logistic regression(SGDClassifier with logloss) on 'data' and check the feature importance\n",
        "    2. Apply SVM(SGDClassifier with hinge) on 'data' and check the feature importance\n",
        "\n",
        "> <b>Task2</b>:\n",
        "    1. Apply Logistic regression(SGDClassifier with logloss) on 'data' after standardization \n",
        "       i.e standardization(data, column wise): (column-mean(column))/std(column) and check the feature importance\n",
        "    2. Apply SVM(SGDClassifier with hinge) on 'data' after standardization \n",
        "       i.e standardization(data, column wise): (column-mean(column))/std(column) and check the feature importance\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tAJNo-t-o8P",
        "outputId": "77e46f00-44de-4422-d295-b18688426726"
      },
      "source": [
        "from sklearn import  linear_model\n",
        "\n",
        "clf=linear_model.SGDClassifier(loss='log', penalty='l2', alpha=0.0001, l1_ratio=0.15, \n",
        "                           fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0,\n",
        "                            epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal',\n",
        "                             eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1,\n",
        "                              n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
        "clf.fit(X,Y)\n",
        "score=clf.score(X, Y)\n",
        "print(\"LR_score:\",score)\n",
        "feature_imp=clf.coef_\n",
        "print(\"LR_feature importance\",feature_imp)\n",
        "clf1=linear_model.SGDClassifier(loss='hinge',penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
        "                                fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True,\n",
        "                                verbose=0, epsilon=0.1, n_jobs=None, random_state=None, \n",
        "                                learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False,\n",
        "                                validation_fraction=0.1, n_iter_no_change=5, class_weight=None, \n",
        "                                warm_start=False, average=False)\n",
        "\n",
        "clf1.fit(X,Y)\n",
        "score1=clf1.score(X, Y)\n",
        "print(\"SVM_SCORE:\",score1)\n",
        "feature_imp1=clf1.coef_\n",
        "print(\"SVM_feature importance\",feature_imp1)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR_score: 0.47\n",
            "LR_feature importance [[11516.82549293 27592.38403388 10754.260146  ]]\n",
            "SVM_SCORE: 0.525\n",
            "SVM_feature importance [[ 8202.71523435 -8846.52371832 10112.34178885]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4U69woxIECd"
      },
      "source": [
        "##obervation.\n",
        "1.As the features are not standardized , its very difficult to analyse the most import feature which favours vaule of y.\n",
        "\n",
        "2.As SGD is a randomized classifier , for each runtime we get different feature weights ,so its difficult to analyise feature importance.\n",
        "\n",
        "3.Score of the model is also very less(approx between 0.4-05) as the data is not standardised ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Oy3noOY-Hf",
        "outputId": "bd2f1b78-4aac-43c2-af9b-335dddc41193"
      },
      "source": [
        "data1=data.copy()\n",
        "\n",
        "Y=data1['y']\n",
        "X1 = data1.drop(['y'], axis=1)\n",
        "standardised_X=(X1-X1.mean())/X1.std()\n",
        "\n",
        "import  sklearn\n",
        "\n",
        "clf3=linear_model.SGDClassifier(loss='log', penalty='l2', alpha=0.0001, l1_ratio=0.15, \n",
        "                           fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0,\n",
        "                            epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal',\n",
        "                             eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1,\n",
        "                              n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
        "clf3.fit(standardised_X,Y)\n",
        "score2=clf3.score(standardised_X, Y)\n",
        "print(\"LR_score\",score2)\n",
        "feature_imp2=clf3.coef_\n",
        "print(\"LR_feature _importance:\",feature_imp2)\n",
        "clf4=linear_model.SGDClassifier(loss='hinge',penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
        "                                fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True,\n",
        "                                verbose=0, epsilon=0.1, n_jobs=None, random_state=None, \n",
        "                                learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False,\n",
        "                                validation_fraction=0.1, n_iter_no_change=5, class_weight=None, \n",
        "                                warm_start=False, average=False)\n",
        "\n",
        "clf4.fit(standardised_X,Y)\n",
        "score3=clf4.score(standardised_X, Y)\n",
        "print(\"SVM_SCore\",score3)\n",
        "feature_imp3=clf4.coef_\n",
        "print(\"SVM_feature_importance\",feature_imp3)\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR_score 0.93\n",
            "LR_feature _importance: [[-1.70591909  1.90908213 11.87340309]]\n",
            "SVM_SCore 0.925\n",
            "SVM_feature_importance [[-1.62599943 -1.82951121 15.16606146]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U9Unjd7JCFB"
      },
      "source": [
        "##OBSERVATION\n",
        "1.Here as the data features are standardized , we can see the F3 has high importance and its easy to interpret also.\n",
        "\n",
        "2.score of the model is also approx 0.9, this shows model fits data better if features are standarised.\n",
        "\n",
        "3.here feature importance value are not very large in +ve or -Ve direction,so its easy to interpret the best feature .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rccr5ly3qAG5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbMnsrxakbhi"
      },
      "source": [
        "<h3><font color='blue'> Make sure you write the observations for each task, why a particular feautre got more importance than others</font></h3>"
      ]
    }
  ]
}